{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import IPython.display as display\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models,transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/libs/\")\n",
    "\n",
    "from transform import BaseTransform\n",
    "from dataset import CustomDataset\n",
    "from loss import LossFunction\n",
    "\n",
    "print(\"Pytorch Version: \", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../data/img/\"\n",
    "cor_path = \"../data/cor_img/\"\n",
    "transform = BaseTransform() #256*256\n",
    "dataset = CustomDataset(data_dir=img_path,cor_dir=cor_path,transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim, condition_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.condition_dim = condition_dim\n",
    "        self.conv1 = nn.Conv2d(3, 64, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 4, 2, 1)\n",
    "        self.fc1 = nn.Linear(128 * 64 * 64 + self.condition_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, latent_dim)\n",
    "        self.fc3 = nn.Linear(1024, latent_dim)\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        condition = condition.view(condition.size(0), -1)\n",
    "        x = torch.cat((x, condition), dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        mu = self.fc2(x)\n",
    "        logvar = self.fc3(x)\n",
    "        return mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, condition_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.condition_dim = condition_dim\n",
    "        self.fc1 = nn.Linear(latent_dim + self.condition_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128 * 64 * 64)\n",
    "        self.deconv1 = nn.ConvTranspose2d(128, 64, 4, 2, 1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(64, 3, 4, 2, 1)\n",
    "\n",
    "    def forward(self, z, condition):\n",
    "        z = torch.cat((z, condition), dim=1)\n",
    "        z = F.relu(self.fc1(z))\n",
    "        z = F.relu(self.fc2(z))\n",
    "        z = z.view(z.size(0), 128, 64, 64)\n",
    "        z = F.relu(self.deconv1(z))\n",
    "        z = torch.sigmoid(self.deconv2(z))\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional VAEモデルの構築\n",
    "class ConditionalVAE(nn.Module):\n",
    "    def __init__(self, latent_dim, condition_dim):\n",
    "        super(ConditionalVAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim, condition_dim)\n",
    "        self.decoder = Decoder(latent_dim, condition_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        mu, logvar = self.encoder(x, condition)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decoder(z, condition)\n",
    "        return recon_x, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再構築誤差の計算\n",
    "def reconstruction_loss(recon_x, x):\n",
    "    # 通常の平均二乗誤差 (MSE) またはクロスエントロピー誤差を使用\n",
    "    mse_loss = nn.MSELoss()  # または nn.BCELoss() など\n",
    "    recon_loss = mse_loss(recon_x, x)\n",
    "    return recon_loss\n",
    "\n",
    "# KLダイバージェンスの計算\n",
    "def kl_divergence(mu, logvar):\n",
    "    # ガウス分布のKLダイバージェンス\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return kl_loss\n",
    "\n",
    "# Conditional VAEの損失関数\n",
    "def vae_loss(recon_x, x, mu, logvar, condition):\n",
    "    recon_loss = reconstruction_loss(recon_x, x)\n",
    "    kl_loss = kl_divergence(mu, logvar)\n",
    "    \n",
    "    # 通常の再構築誤差とKLダイバージェンスに重みを掛けて合算\n",
    "    beta = 1.0  # KLダイバージェンスの重み（調整が必要）\n",
    "    vae_loss = recon_loss + beta * kl_loss\n",
    "    \n",
    "    return vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのインスタンス化\n",
    "z_dim = 128  # 潜在変数の次元\n",
    "condition_dim = 256\n",
    "vae = ConditionalVAE(z_dim, condition_dim)\n",
    "\n",
    "# 最適化アルゴリズムと学習率\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのトレーニング\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x, condition = batch[0].to(device), batch[1].to(device)\n",
    "        recon_x, mu, logvar = vae(x, condition)\n",
    "        loss = vae_loss(recon_x, x, mu, logvar, condition)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
